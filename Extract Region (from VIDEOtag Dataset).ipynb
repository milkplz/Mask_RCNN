{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "from model import log\n",
    "import coco\n",
    "import visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model & Load Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "# config.display()\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare COCO categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare VIDEOtag, COCO category 맵핑 데이타"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VIDEOtag, COCO category 맵핑 데이타\n",
    "map_data = open(\"assets/json/category.json\").read()\n",
    "tmp_videotag_coco_cate_map = json.loads(map_data)[\"categories\"]\n",
    "\n",
    "# dictionary로 생성\n",
    "videotag_coco_cate_map = {}\n",
    "for cate_data in tmp_videotag_coco_cate_map:\n",
    "    videotag_coco_cate_map[cate_data['id']] = cate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare VIDEOtag Dataset\n",
    "\n",
    "### 0101~0102 dataset\n",
    "https://s3.ap-northeast-2.amazonaws.com/f-machine-learning-dataset/datasets/fingerplus/0101_0102.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = open(\"dataset/videotag/0101_0102/instances.json\").read()\n",
    "data = json.loads(json_data)\n",
    "\n",
    "videotag_anno = data['annotations']\n",
    "videotag_imgs = data['images']\n",
    "videotag_cate = data['categories']\n",
    "\n",
    "\n",
    "videotag_img_anno_ids = {}\n",
    "videotag_anno_dic = {}\n",
    "videotag_cate_dic = {}\n",
    "\n",
    "for anno in videotag_anno:\n",
    "    videotag_anno_dic[anno['id']] = anno\n",
    "    \n",
    "for cate in videotag_cate:\n",
    "    videotag_cate_dic[cate['id']] = cate\n",
    "        \n",
    "for image in videotag_imgs:\n",
    "    anno_ids = []\n",
    "    image_id = image['id']\n",
    "    \n",
    "    for anno in videotag_anno:\n",
    "        anno_img_id = anno['image_id']\n",
    "        anno_id = anno['id']\n",
    "        if anno_img_id == image_id:\n",
    "            anno_ids.append(anno_id)\n",
    "    # if not len(annos) == 0:\n",
    "    videotag_img_anno_ids[image_id] = anno_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199606\n",
      "['297282', '297283']\n"
     ]
    }
   ],
   "source": [
    "print(videotag_imgs[1]['id'])\n",
    "print(videotag_img_anno_ids[videotag_imgs[1]['id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect & Extract Region\n",
    "\n",
    "annotations : [{\n",
    "  area,         // Number - 영역 넓이(w*h)\n",
    "  bbox,         // [x,y,width,height], (Array(4))\n",
    "  category_id,  // int\n",
    "  id,           // int\n",
    "  image_id,     // int\n",
    "  iscrowd,      // 0 or 1 (get anns for given crowd label (False or True))\n",
    "  segmentation  // Array - mask 데이터 (RLE or [polygon])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1081\n",
      "1/1081\n",
      "결과값 비교 coco ['person']\n",
      "결과값 비교 videotag ['모자', '재킷']\n",
      "----------------------------------------------------------------------\n",
      "2/1081\n",
      "saved bbox {'id': '297292', 'x_pos': 0.6097560975609756, 'y_pos': 0.7074303405572755, 'image_id': '199607', 'category_id': 'B09', 'bbox': [268, 148, 168, 200]}\n",
      "결과값 비교 coco ['person', 'person', 'person', 'chair', 'handbag', 'cell phone']\n",
      "결과값 비교 videotag ['시계', '선글라스']\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type 'int32' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-9530c027ebef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/videotag/0101_0102/videotag_anno.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideotag_anno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/videotag/0101_0102/extract_annotations.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'int32' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "def getAnnosByIds(anno_ids):\n",
    "    result = []\n",
    "    for anno_id in anno_ids:  \n",
    "        result.append(videotag_anno_dic[anno_id])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def saveBbox(anno_id, bbox):\n",
    "    for anno in videotag_anno:\n",
    "        if anno['id'] == anno_id:\n",
    "            anno['bbox'] = bbox\n",
    "            print('saved bbox', anno)\n",
    "            break\n",
    "\n",
    "extract_annotations = []\n",
    "\n",
    "\n",
    "###################################################################\n",
    "# 모든 이미지에 대하여 predict를 실시한다.\n",
    "###################################################################\n",
    "vt_img_total = len(videotag_imgs)\n",
    "for vt_img_current, vt_img in enumerate(videotag_imgs): \n",
    "    \n",
    "    if vt_img_current > 2:\n",
    "        break;\n",
    "    \n",
    "    print(str(vt_img_current)+'/'+str(vt_img_total))\n",
    "    img_id = vt_img['id']\n",
    "    \n",
    "    \n",
    "    ###################################################################\n",
    "    # videotag image에 등록되어 있느 annotation이 있는지 확인 후, 로드\n",
    "    ###################################################################\n",
    "    vt_annos = getAnnosByIds(videotag_img_anno_ids[img_id])\n",
    "    \n",
    "    if len(vt_annos) == 0:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    ###################################################################\n",
    "    # videotag image이 로드\n",
    "    ###################################################################\n",
    "    img_path = os.path.join(ROOT_DIR, 'dataset/videotag/0101_0102/images', vt_img['file_name']) \n",
    "    image = skimage.io.imread(img_path)\n",
    "    # If grayscale. Convert to RGB for consistency.\n",
    "    if image.ndim != 3:\n",
    "        image = skimage.color.gray2rgb(image)\n",
    "        \n",
    "    height, width = image.shape[:2]    \n",
    "        \n",
    "    \n",
    "    ###################################################################\n",
    "    # Run detection\n",
    "    ###################################################################\n",
    "    results = model.detect([image], verbose=0)\n",
    "\n",
    "    # Result\n",
    "    r = results[0]\n",
    "    \n",
    "    rois = r['rois'] # y1, x1, y2, x2\n",
    "    scores = r['scores']\n",
    "    masks = r['masks'] # (height, width, 검출된 데이타 갯수)\n",
    "    class_ids = r['class_ids']\n",
    "    \n",
    "    \n",
    "    # 확인용\n",
    "    confirm_coco_classes = [];\n",
    "    confirm_vt_classes = [];\n",
    "    confirm_vt_anno_points = []\n",
    "    for vt_anno in vt_annos:\n",
    "        point_x = int(width*vt_anno['x_pos'])\n",
    "        point_y = int(height*vt_anno['y_pos'])\n",
    "        confirm_vt_anno_points.append([point_y-5, point_x-5, point_y+5, point_x+5])\n",
    "        \n",
    "        vt_cate_id = vt_anno['category_id']\n",
    "        vt_cate_data = videotag_cate_dic[vt_cate_id]\n",
    "        confirm_vt_classes.append(vt_cate_data['name'])\n",
    "                \n",
    "    is_found = 0\n",
    "    \n",
    "    ###################################################################\n",
    "    # 추출된 Annotation을 VIDEOtag Annotation과 비교\n",
    "    ###################################################################\n",
    "    for index, score in enumerate(scores):\n",
    "#         if score < 0.9:\n",
    "#             continue\n",
    "        \n",
    "        image_id = image_id\n",
    "        category_id = class_ids[index]\n",
    "        category_name = class_names[category_id]\n",
    "        roi = rois[index]\n",
    "        bbox = [roi[1], roi[0], roi[3] - roi[1], roi[2] - roi[0]]\n",
    "        mask = masks[:, :, index]\n",
    "        '''\n",
    "        segmentation = maskUtils.encode(np.asfortranarray(mask))\n",
    "        rle = maskUtils.decode(segmentation)\n",
    "#         m = maskUtils.decode(rle)\n",
    "        print('segmentation', rle)\n",
    "        area = maskUtils.area(segmentation)\n",
    "        '''\n",
    "        annotation = {}\n",
    "        annotation['bbox'] = bbox\n",
    "        annotation['category_id'] = category_id\n",
    "        annotation['id'] = ''\n",
    "        annotation['image_id'] = image_id\n",
    "        annotation['iscrowd'] = 0\n",
    "        '''\n",
    "        annotation['area'] = area\n",
    "        annotation['segmentation'] = segmentation\n",
    "        '''\n",
    "        # 확인용\n",
    "        confirm_coco_classes.append(category_name)\n",
    "        \n",
    "        ###################################################################\n",
    "        # coco model에서 검출된 annotation들이 videotag annotation(정답)들과 비교하여\n",
    "        # 일치할 경우가 있을 때, 해당 videotag annotation에 bbox정보를 추가한다.\n",
    "        ###################################################################\n",
    "        for vt_anno in vt_annos:\n",
    "            vt_anno_id = vt_anno['id']\n",
    "            vt_cate_id = vt_anno['category_id']\n",
    "            vt_cate_data = videotag_cate_dic[vt_cate_id]\n",
    "            vt_cate_name = vt_cate_data['name']\n",
    "            \n",
    "            point_x = int(width*vt_anno['x_pos'])\n",
    "            point_y = int(height*vt_anno['y_pos'])\n",
    "            \n",
    "            coco_cate_ids = videotag_coco_cate_map[vt_cate_id]['coco_ids']\n",
    "            if len(coco_cate_ids) == 0:\n",
    "                continue\n",
    "                \n",
    "            # NOTE: 포인트가 마스크 영역에 속하는 확인\n",
    "            if mask[point_y][point_x] == 0:\n",
    "                continue\n",
    "            \n",
    "#             vt_anno['bbox'] = bbox\n",
    "            saveBbox(vt_anno_id, bbox)\n",
    "            extract_annotations.append(annotation)\n",
    "            \n",
    "            for coco_cate_id in coco_cate_ids:\n",
    "                if coco_cate_id == category_id:\n",
    "                    print('찾았다', 'videotag : '+vt_cate_name, 'coco : '+category_name)\n",
    "#                     vt_anno['bbox'] = [1,1,1,1]\n",
    "                    is_found = 1\n",
    "                    break\n",
    "                    \n",
    "    print('결과값 비교 coco', confirm_coco_classes)\n",
    "    print('결과값 비교 videotag', confirm_vt_classes)\n",
    "    print('----------------------------------------------------------------------')\n",
    "    \n",
    "    if is_found:\n",
    "        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'], confirm_videotag_anno_points)\n",
    "        \n",
    "import json\n",
    "with open('dataset/videotag/0101_0102/videotag_anno.json', 'w') as outfile:\n",
    "    json.dump(videotag_anno, outfile)\n",
    "\n",
    "with open('dataset/videotag/0101_0102/extract_annotations.json', 'w') as outfile:\n",
    "    json.dump(extract_annotations, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
